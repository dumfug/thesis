\chapter{Related Work}


\section{Graph Theory Basics}
\label{sec:graph-theory-basics}

In this section some graph theory related notation is defined which is used during this thesis.
It is for the most part based on~\cite{Thulasiraman1992} and on~\cite{Diestel2012}.
A graph is a mathematical construct that can be used to model and explore the relationship between objects.
More formally, a graph is a ordered pair of finite sets \(G = (V, E)\), whereas \(V\) denotes the set of \emph{vertices} (i.e., the objects) and \(E \subseteq [V]^{2} \) the set of \emph{edges} (i.e., the relationships between the objects).
It is common to write \(V(G)\) and \(E(G)\) to refer to the set of vertices  respectively the set of edges, that are associated with a graph \(G\).
An edge \(\{v_1, v_2\} \in E(G)\) is an unordered pair of two vertices.
This means that there is no distinction between the two edges \(\{v_1, v_2 \}\) and \(\{v_2, v_1\}\).
A graph with this property is called a \emph{undirected} graph.
However, it is also possible to define edges as ordered pairs, so that each edge does have a start- and endpoint.
Such a graph is called a \emph{directed} graph.
An edge of the form \(\{v_i, v_i\} \in E(G)\) is called a \emph{self-loop} of the vertex \(v_i\).
Furthermore, it is possible that two distinct vertices are joined by multiple edges.
Such edges are referred to as \emph{parallel} edges.
A graph that has no parallel edges and no self-loops is called a \emph{simple} graph.
Figure~\ref{fig:example_graphs} depicts a example for a simple graph and for a graph with multiple edges and a self-loop vertex.
All further mentions and definitions for graphs are referring to undirected simple graphs unless stated otherwise.
It is also possible to perform operations on graphs.
For example, the union of two graphs \(G_{1} = (V_{1}, E_{1})\) and \(G_{2} = (V_{2}, E_{2})\) results in a graph \(G = (V_{1} \cup V_{2}, E_{1} \cup E_{2})\).
Other binary operations, such as the intersection of two graphs, can be done analogous.
There are unary operations on graphs (e.g., the removal of vertices and edges) as well.

\begin{figure}[h]
   \centering
   \begin{subfigure}[t]{0.45\textwidth}
     \centering
     \begin{tikzpicture}[node/.style={circle,fill=red!70,minimum size=1em,inner sep=3pt]}]
       \node[node] (1) at (0, 0) {};
       \node[node] (2) at (-1, -1.5)  {};
       \node[node] (3) at (1, -1.5) {};
       \node[node] (4) at (-1, -3) {};
       \node[node] (5) at (1, -3) {};

       \draw (1) -- (3);
       \draw (1) -- (2) -- (4) -- (5) -- (3) -- (2);
     \end{tikzpicture}
     \caption{A undirected simple graph.}
   \end{subfigure}
   ~
   \begin{subfigure}[t]{0.45\textwidth}
     \centering
     \begin{tikzpicture}[every loop/.style={}, node/.style={circle,fill=red!70,minimum size=1em,inner sep=3pt]}]
       \node[node] (1) at (0, 0) {};
       \node[node] (2) at (-1, -1.5)  {};
       \node[node] (3) at (1, -1.5) {};
       \node[node] (4) at (0, -3) {};

       \draw (1) -- (2);
       \draw (1) -- (3) -- (4);
       \path (2) edge [bend left] (4);
       \path (2) edge [bend right] (4);
       \path (3) edge [bend left] (1);
       \path (3) edge [bend right] (1);
       \draw (4) edge [in=-50,out=-130,loop] (4);
     \end{tikzpicture}
     \caption{A undirected graph with a self-loop and parallel edges.}
   \end{subfigure}

   \caption[Examples for graphs]{Graphical representation of two graphs with different properties.
   The vertices are represented by red dots and the edges are the line segments between them.}
\label{fig:example_graphs}
\end{figure}

The \emph{order} of a graph is its number of vertices (i.e., the cardinality of the vertex set) and is denoted as \(n = |V(G)|\).
The neighborhood of a vertex \(v_i\) is defined as \(N(v_i) = \{v_j \in V(G) : \{v_i, v_j \} \in E(G)\}\).
It is the set of vertices that are \emph{adjacent} to the vertex \(v_i\).
The cardinality of this set is called the \emph{degree} of the vertex and is denoted as \(d(v_i) = |N(v_i)|\).
A vertex without any neighbors (i.e., with a degree of zero) is called \emph{isolated}.
It is also often very useful to measure degree properties for the graph.
For example, the \emph{minimum degree} \(\delta(G) = \min\{d(v_i) : v_i \in V(G)\}\), the \emph{maximal degree} \(\Delta(G) = \max\{d(v_i) : v_i \in V(G)\}\), and the \emph{average degree} \(d(G) = \frac{1}{n} \sum_{v_i \in V(G)} d(v_i)\).
Another way to calculate the average degree is \(d(G) = \frac{2|E|}{n}\), due to the fact that each edge is counted twice during the summation of the vertex degrees.
These global measures can be used to get an insight in the basic structure of the graph.
Another global property related to the degree is the \emph{degree distribution} \(p\)~\cite{Barabasi2016} of a graph.
It yields the probability that that a randomly selected vertex has a degree of \(k\).
Since it is a probability distribution \(\sum_{k=0}^\infty p(k) = 1\) must hold.
The degree distribution for a given graph can be calculated by using \(p(k) = \frac{|\{v \in V(G) \,:\, d(v) = k\}|}{n}\) (i.e., calculating the normalized histogram).

A \emph{path} on a graph can be defined as a finite sequence of vertices \(v_1,v_2,\dots,v_k\), such that between any consecutive pair of vertices exist a edge in the graph.
Furthermore, all edges between the vertices and the vertices itself must be distinct.
The first and the last vertices in the sequence are called the \emph{end vertices} or \emph{terminal vertices} of the path.
The \emph{path length} is the number of edges on the path.
Two vertices are \emph{connected} if it is possible to find a path with these two vertices as end points.
A vertex is, by definition, connected to itself.
If there exists a path between all pairs of vertices, then the graph is called connected.
It is possible to partition the vertex and edge set of a not connected graph in such a way that there are no edges between vertices in different partitions.
These partitions are called the \emph{components} of the graph.

The \emph{clustering coefficient} of a vertex is a measure for the cliquishness of its neighborhood, and was introduced by \citet{Watts1998}.
A \emph{clique} in a graph is a subset of vertices, such that there exists an edge between every pair of vertices in this set.
The clustering coefficient \(C(v_i)\) is defined as the fraction of possible edges between the neighbors of the vertex \(v_i\).
There are at most \(\binom{d(v_i)}{2} = \frac{d(v_i)(d(v_i) - 1)}{2}\) possible edges between vertices in the neighborhood.
Therefore, the clustering coefficient can be calculated using \autoref{eq:clustering-coefficient}.

\begin{equation}
 C(v_i) = \frac{2 \, |\{\{v_j, v_k\} \in E(G) : v_j \in N(v_i) \wedge v_k \in N(v_i)\}| }{d(v_i)(d(v_i) - 1)}
 \label{eq:clustering-coefficient}
\end{equation}

This is, of course, a local property of one vertex and is, therefore, sometimes called \emph{local clustering coefficient}.
However, it is also often useful to consider the average clustering coefficient \(\bar{C} = \frac{1}{n} \sum_{v(i) \in V(G)} C(v_i)\) of the graph.
Figure~\ref{fig:clustering-coefficient-examples} shows some examples for neighborhoods with different clustering coefficients.
There is another definition of a \emph{global clustering coefficient}, which is also often called \emph{transitivity}~\cite{Boccaletti2006}.
It is the ratio of triangles (i.e., cliques consisting of exactly three vertices) to the number connected triples in the graph (see \autoref{eq:global-clustering-coefficient}).
A connected triple is made up of three vertices as well, but does only have two edges.
Hence, a triangle consists of exactly three triples.
The global clustering coefficient is a measure the extent of transitive connections in the graph (i.e., if there is a edge between vertices A and B, and between B and C, how likely is it that there is also an edge between A and C).

\begin{equation}
 T = \frac{3 \times \text{\# of triangles}}{\text{\# of connected triples of vertices}}
 \label{eq:global-clustering-coefficient}
\end{equation}

\begin{figure}[h]
   \centering
   \begin{subfigure}[t]{0.31\textwidth}
     \centering
     \begin{tikzpicture}[node/.style={circle,fill=red!70,minimum size=1em,inner sep=3pt]}, neighbor/.style={circle,fill=blue!70,minimum size=1em,inner sep=3pt]}]
       \node[text width=6em, align=center] at (0, 0.75)  {\(C(red) = 0\)};
       \node[node] (1) at (0, 0) {};
       \node[neighbor] (2) at (-1, -1)  {};
       \node[neighbor] (3) at (1, -1) {};
       \node[neighbor] (4) at (-1, -2)  {};
       \node[neighbor] (5) at (1, -2) {};

       \foreach \p in {2,3,4,5}{\draw (\p) -- (1); }
     \end{tikzpicture}
     \caption{In this example none of the four neighbors shares a edge with any other neighbor of the red vertex.
     Therefore, the clustering coefficient of the red vertex is \(\frac{0}{6} = 0\).}
   \end{subfigure}
   ~
   \begin{subfigure}[t]{0.31\textwidth}
     \centering
     \begin{tikzpicture}[node/.style={circle,fill=red!70,minimum size=1em,inner sep=3pt]}, neighbor/.style={circle,fill=blue!70,minimum size=1em,inner sep=3pt]}]
       \node[text width=6em, align=center] at (0, 0.75)  {\(C(red) = 0.5\)};
       \node[node] (1) at (0, 0) {};
       \node[neighbor] (2) at (-1, -1)  {};
       \node[neighbor] (3) at (1, -1) {};
       \node[neighbor] (4) at (-1, -2)  {};
       \node[neighbor] (5) at (1, -2) {};

       \foreach \p in {2,3,4,5}{\draw (\p) -- (1); }
       \draw (2) -- (4);
       \draw (3) -- (5);
       \draw (3) -- (2);
     \end{tikzpicture}
     \caption{Here are half of the possible edges between the neighbors are present.
     The clustering coefficient of the red vertex is \(\frac{3}{6} = \frac{1}{2}\).}
   \end{subfigure}
   ~
   \begin{subfigure}[t]{0.31\textwidth}
     \centering
     \begin{tikzpicture}[node/.style={circle,fill=red!70,minimum size=1em,inner sep=3pt]}, neighbor/.style={circle,fill=blue!70,minimum size=1em,inner sep=3pt]}]
       \node[text width=6em, align=center] at (0, 0.75)  {\(C(red) = 1\)};
       \node[node] (1) at (0, 0) {};
       \node[neighbor] (2) at (-1, -1)  {};
       \node[neighbor] (3) at (1, -1) {};
       \node[neighbor] (4) at (-1, -2)  {};
       \node[neighbor] (5) at (1, -2) {};

       \foreach \p in {1,2,3,4,5}{ \foreach \q in {1,2,3,4,5}{\draw (\p) -- (\q); }}
     \end{tikzpicture}
     \caption{The neighbors of the red vertex form a clique.
     Hence, the clustering coefficient of the red vertex is \(\frac{6}{6} = 1\).}
   \end{subfigure}

   \caption[Clustering coefficient examples]{Examples for the clustering coefficient of a vertex with a small neighborhood.
   The blue vertices are the neighbors of the red vertex.
   The possible number of edges between the four neighbors is \(\binom{4}{2} = 6\).}
\label{fig:clustering-coefficient-examples}
\end{figure}


%% ========================================================================
%% ========================================================================


\section{Social Networks}
\label{sec:social-networks}

In the real-world it is common to use graphs to model the complex systems that are arising.
For example, the web can be represented as a graph, where the vertices correspond to websites and the edges are the hyperlinks between them.
Another use case are large infrastructure networks, such as power grids.
In a graph that represents such a power grid network vertices represent things like power stations or transformers and edges the power lines between them.
However, when modeling these large networks it common to use a slightly different terminology~\cite{Barabasi2016}.
Vertices are often called \emph{nodes} and edges are called \emph{links} in the context of networks.

Social networks~\cite{Newman2010} are another type of network that can benefit from the usage of graph theory methods.
The study of these networks is considered to be a part of the field of sociology and researchers may also use slightly different terminology for the vertices and edges in their work.
Nodes (or vertices) often represent people in social networks and are also sometimes referred to as \emph{actors}.
However, it is also possible that nodes depict other entities, such as a departments, companies, or countries (i.e., larger groups of people).
The links (or edges) between these entities can mean, depending of the context, different things as well and are sometimes also referred to as \emph{ties}.
For example, links between persons can show social relationships (e.g., friendships), collaborations in projects (e.g., co-authorship of a scientific papers), or other social interactions.
Links between companies could represent trading relationships or the like.
Often social networks are only mentioned in relation to large online communities, such as Facebook or Twitter, but there is no necessity that a social network must exist in an online form.
The network of acquaintances or friends in a school is also considered as a social network.
Figure~\ref{fig:karate-club-network} shows a famous example of a small real-world social network.

\myfig{karate_club_network}
      {width=0.6\textwidth,height=0.6\textheight}
      {Zachary's karate club network~\cite{Zachary1977} is a social network that shows the relationship between 34 members of a university-based karate club in the US in the early 1970's.
      There exists an edge between two members if there were social interactions outside of the normal club activities (i.e., two members are considered as friends).
      The graph shows a separation into two groups (red and blue nodes) due to a dispute in the club.}
      {Zachary's karate club network}
      {fig:karate-club-network}

Two fundamental terms in social network analysis are \emph{dyads} and \emph{triads}~\cite{Wasserman1994}.
These two concepts describe the relationship between multiple actors.
A \emph{dyad} denotes the linkage between a pair of actors.
It is a very common research topic to understand the pairwise relationships in social networks.
A \emph{triad} on the other hand describes triples of actors and the ties between them.
This concept is especially important for the question of transitivity of certain relationships.
A example for this would be the question \enquote{is the friend of my friend also my friend?}.
\todo{strong/weak ties description}
\todo{egocentric networks}

A property of many real-world social networks is a \emph{community structure}~\cite{Girvan2002}.
Communities are groups of actors that are more connected to actors in the same group, than to actors in a different one.
This basically means that there exists subsets of densely linked nodes in the network with very few links to other subsets.
The network shown in figure~\ref{fig:karate-club-network} has two known communities characterized by different node colors.
The detection of community structures in networks is a very import research topic, since the identified communities may correspond to actual social groupings.
For example, the detected communities in a social network that models the friendship between students may represent the real corresponding social groups (i.e., the circles of friends).
There is a variety of different methods and approaches to perform this task.
Examples are approaches based on hierarchical clustering, or edge betweenness (i.e., the number of shortest paths going through an edge).

Another attribute that many social networks share is that they are \emph{scale-free networks}~\cite{Barabasi2016}.
Formally, a network is a scale-free network if its degree distribution is a \emph{power-law distribution} (i.e., \(p(k) \sim k^{-\gamma}\), where \(\gamma\) is the parameter of the distribution that denotes the degree exponent).
The value for \(\gamma\) for most real-world (social) networks is in the range between 2 and 3.
A consequence of the power-law distribution is that the distribution of the degrees is right-skewed with a long tail.
This means that there is a large number of nodes in the network that have only a few links (i.e., a small degree) but there is also the chance that there exists a few nodes with a very high degree.
Such nodes are usually called \emph{hubs} and may correspond in the context of social networks to very influential actors that can play an important role in the network.


%% ========================================================================
%% ========================================================================


\section{Time-varying Networks}
\label{sec:time-varying-networks}

This section contains an overview on the concept of time-varying networks~\cite{Holme2012, Holme2015}.
Since this type of network is used in many different scientific fields it also has a variety of names.
For example, temporal networks, dynamic networks, evolving graphs, or the name that is mainly used in this thesis, time-varying networks.
As already mentioned in the section about social networks, the structure, or topology, of networks can be used to understand dynamic processes and their behavior.
However, there are a lot of dynamical processes that are modeled using networks, in which the links are not active all the time.
One example would be a communication network, such as the network of phone calls between users.
Another example would social or collaboration network, where actors do not interact constantly but in irregular intervals.
These link activation at certain times can, however, be very important to explain the dynamic process and are simply lost when approximated by a static graph.
So the idea of time-varying networks is to introduce another dimension (i.e., time) to the network and move the information of when something happens from the dynamic process to the network itself.
As a general rule, a time-varying network is applicable when the structure (i.e., the topology) of the system and the temporal process are connected to each other.
This means that the time scale on which the network itself evolves should be similar to the time scale of the dynamic process that takes place on it.
For example, a time-varying network is not a suitable model for the internet, since the the infrastructure (i.e., the topology) changes very slowly in comparison to the transmission of the packages that are routed through the network (i.e., the dynamic process).

The underlying concept of time-varying networks is called \emph{contacts} and can be seen as interactions between two nodes at a certain time.
The duration of the interaction is negligible and thus assumed to be instantaneous.
Contacts can be interpreted as an extension of links in the static network.
The unordered pair \(\{v_{i}, v_{j}\}\) becomes a ordered triple \((v_{i}, v_{j}, t)\).
The order is in this case important, since the third object in the triple must refer to the interaction time \(t\) between the nodes \(v_{i}\) and \(v_{j}\).
The usage of static networks in models for dynamic processes, that represents some time-depended sequence of contacts between pairs of nodes, often results in a loss of information, that can be regained using time-varying networks.
However, these temporal networks also introduce more complexity to the model and one have to weight the gain of information versus the extra effort.
Especially in the case that the knowledge of how often something between two actors in the network happens is more important than when exactly something happens is a use case for weighted networks~\cite{Newman2010}. \todo{describe weighted graphs in the graph theory basics, since it is also relevant for other things}
This type of network introduces a mapping between the set of edges and values that represent the strength of the link.
See \autoref{fig:weighted-network-example} for an illustration of a simple weighted network.
However, a simple graph without weights can also be used to approximate the interaction sequence of a time-varying network~\cite{Holme2013}.
The idea is to calculate a total weight for each pair of nodes in the network.
If the weight exceeds a certain threshold \(\Omega \in \mathbb{R}_{0}^{+}\) then there will be an edge between the two nodes in the static approximation.
Each contact between two contacts in the sequence \(C\) contributes a part to the total weight.
However, the weight of the contribution to the total weight decays exponentially.
Hence, the total weight \(\omega_{i,j}\) between two nodes \(v_{i}\) and \(v_{j}\) is \(\omega_{i,j} = \sum_{(v_{i}, v_{j}, t) \in C} \exp(-t / \tau)\), where \(\tau\) is an additional parameter that controls the exponential decay.
For a static approximation that should contain an edge if there was at least one contact between the two nodes the threshold can be set to \(\Omega = 0\).
Networks that are generated using this approach are called exponential-threshold networks.

There are also many different possibilities to represent a temporal network without the loss of information.
The simplest way to to this is by using the actual contact sequences.
A contact sequence is basically a list that contains all the contact triples.
This is a very raw form data (i.e., in essence a spreadsheet with three columns) and is therefore very easy to parse and to use in algorithms, but is not very well suited for the analysis of the underlying dynamic process by humans due to the lack of illustrations.
Another way to represent time-varying networks are graph sequences.
The idea here is to generate a static graph that contains all contacts between nodes for a given time step.
This method has the advantage that all tools that work for static graphs can be applied to each of the graphs in the sequence.
The problem with this representation is, that the time resolution should be rather low to avoid the creation of graphs with no, or only a few, edges for most time steps.
\autoref{fig:graph-sequence-example} depicts an example of a graph sequence for a time-varying network with four nodes.
There are also more visual-focused representation methods.
One example would be assigning a time series of time stamp of the contacts between two nodes to the corresponding link in the static network (see \autoref{fig:time-stamp-edges-example} for an example).
This allows the usage of the variety of graph layout algorithms to visualize the network, but does not work very well for large networks due to the lack of space for the time stamps on the links and the large numbers of nodes.
Another idea is to visualize the time-varying network using a timeline of contacts.
The interactions between nodes (i.e., the tuple of nodes that are interacting with each other) are placed on one axis and the time is placed on the other one.
A marker is placed for each pair that interacts at a certain time.
This allows the visual detection of interaction patterns.
However, similar to the last representation methods, this one also only reasonable for small networks.
\autoref{fig:timeline-example} shows an example for this type of representation.

\begin{figure}
   \centering
   \begin{subfigure}[t]{0.39\textwidth}
     \centering
     \begin{tikzpicture}[node/.style={circle,fill=red!70,minimum size=1em,inner sep=2pt]}]

       \node[node] (1) at (0, 2) {1};
       \node[node] (2) at (2, 2) {2};
       \node[node] (3) at (0, 0) {3};
       \node[node] (4) at (2, 0) {4};

       \draw[line width=5.00pt] (1) -- (2);
       \draw[line width=2.50pt] (1) -- (4);
       \draw[line width=1.25pt] (2) -- (4);
       \draw[line width=1.25pt] (3) -- (4);
     \end{tikzpicture}

   \caption{Static approximation of the contact sequence as a weighted network.
   The width of the lines between the nodes represent the strength (i.e., the weight) of the edges.
   The thicker the line the higher the weight.}
   \label{fig:weighted-network-example}
   \end{subfigure}
   ~
   \begin{subfigure}[t]{0.58\textwidth}
     \centering
     \begin{tikzpicture}[node/.style={circle,fill=red!70,minimum size=1em,inner sep=2pt]}]

       \foreach \t in {0, 1, 2} {
           \node[text width=6em, align=center] at (0.5+\t*2.5, -0.75)  {\(t=\t\)};
           \node[node] (1_\t) at (0+\t*2.5, 1) {\scriptsize 1};
           \node[node] (2_\t) at (1+\t*2.5, 1) {\scriptsize 2};
           \node[node] (3_\t) at (0+\t*2.5, 0) {\scriptsize 3};
           \node[node] (4_\t) at (1+\t*2.5, 0) {\scriptsize 4};
       }

       \draw (1_0) -- (2_0);
       \draw (1_0) -- (4_0);
       \draw (3_0) -- (4_0);
       \draw (2_1) -- (4_1);
       \draw (1_1) -- (2_1);
       \draw (1_2) -- (2_2);
       \draw (1_2) -- (4_2);
     \end{tikzpicture}

   \caption{Visualization of the graph sequence representation of the three time steps of a time-varying network.
   There exists an edge in a graph at time \(t\) if there was a contact between the two nodes at this time step.}
   \label{fig:graph-sequence-example}
   \end{subfigure}

   \begin{subfigure}[t]{0.39\textwidth}
     \centering
     \begin{tikzpicture}[node/.style={circle,fill=red!70,minimum size=1em,inner sep=2pt]}]

       \node[node] (1) at (0, 2) {1};
       \node[node] (2) at (2, 2) {2};
       \node[node] (3) at (0, 0) {3};
       \node[node] (4) at (2, 0) {4};

       \draw (1) -- (2) node[midway, above] {0,1,2};
       \draw (1) -- (4) node[midway, right] {0,2};
       \draw (2) -- (4) node[midway, right] {1};
       \draw (3) -- (4) node[midway, above] {0};
     \end{tikzpicture}

   \caption{A graph that contains an edge between two nodes if there was at least one contact between them.
   Furthermore, the edges are annotated with a time series of time steps that indicate when the interactions took place.}
   \label{fig:time-stamp-edges-example}
   \end{subfigure}
   ~
   \begin{subfigure}[t]{0.58\textwidth}
     \centering
     \begin{tikzpicture}[contact/.style={rectangle,fill=black,inner sep=0pt,minimum size=4pt]}]

       \draw (0, 2) node[left] {(1,2)} to (6.5, 2);
       \draw (0, 1.5) node[left] {(1,4)} to (6.5, 1.5);
       \draw (0, 1) node[left] {(2,4)} to (6.5, 1);
       \draw (0, 0.5) node[left] {(3,4)} to (6.5, 0.5);

       \draw[->, line width=1.5pt] (0, 0) to (7, 0) node[below] {t};
       \node[below] at (1, 0) {0};
       \node[below] at (3, 0) {1};
       \node[below] at (5, 0) {2};

       \node[contact] at (1, 2) {};
       \node[contact] at (1, 1.5) {};
       \node[contact] at (1, 0.5) {};
       \node[contact] at (3, 2) {};
       \node[contact] at (3, 1) {};
       \node[contact] at (5, 2) {};
       \node[contact] at (5, 1.5) {};
     \end{tikzpicture}

   \caption{Visualization of the contact sequence as a timeline of contacts.
   The vertical axis shows the interactions that happened between the nodes in the network and the horizontal axis shows the three time steps.
   There is a marker, depicted as a black rectangle, if there was a contact between the pair at a given time \(t\).}
   \label{fig:timeline-example}
   \end{subfigure}

   \caption[Graphical representations of time-varying networks]{Figures \subref{fig:graph-sequence-example}--\subref{fig:timeline-example} show different visualizations for the contact sequence \((1, 2, 0), (1, 4, 0), (3, 4, 0), (1, 2, 1), (2, 4, 1), (1, 2, 2), (1, 4, 2)\).
   Figure \subref{fig:weighted-network-example} shows a static network of the same contact sequence where the number of contacts between two nodes is reflected by the edge weights.}
\end{figure}
\todo{fix different sizes for nodes in subfigures (a) and (c)}

It is also noteworthy that most of the introduced measures for networks do not apply for temporal networks or must be redefined, respectively extended.
For example, the concept of degree distributions does not exists in this context.
But there are new measures like the \emph{inter-contact time distributions}, which describe the frequency of the time between contacts between either a specific pair of nodes or any two nodes.
Paths also cannot be used in temporal networks and are replaced by measures like \emph{latency} (i.e., how long since the last contact between two nodes) or \emph{temporal distance} (i.e., how long does it take to get from one node to another while taking the contacts into account).
There is also the idea, and many approaches, to extend community detection mechanisms for the usage in time-varying networks by running community detection algorithms for a static approximation of the network at time \(t\) and then including community information from previous time steps.


%% ========================================================================
%% ========================================================================


\section{Network Models}
\label{sec:network-models}

This section contains descriptions of different network models.
These models can be used to build graphs that fulfill different properties.
They are often a useful tool to model some type of real-world network (e.g., a social network) to gain a deeper understanding on the processes that create these networks.

\subsection{The Erdős-Rényi Model}

The Erdős–Rényi (ER) model~\cite{Erdos1959, Newman2010} was in its first form described by the two famous mathematicians Paul Erdős and Alfréd Rényi in 1959.
The model generates a random graph with \(n\) nodes and \(m\) links.
It chooses one of the \(\binom{\binom{n}{2}}{m}\) possible graphs of this size with equal probability at random.
The idea is that large, complex networks often seem random and can be examined using random graphs and statistical methods~\cite{Barabasi2002}.
Therefore,this is a very simple, yet powerful, model to explore some effects that take place in real-world systems.
It is also often called \(G(n, m)\).
There is another model that is very similar to the \(G(n, m)\) model, called the \(G(n, p)\) model.
Here is the number of links not fixed beforehand, but determined by \(p\), the probability of the presence of a link between any pair of nodes in the network.
Hence, the edges of a random network are determined by flipping a biased coin for each of the \(\binom{n}{2}\) possible edges.

The probability for an arbitrary network with exactly \(m\) links under this model is \(p^{m} (1-p)^{\binom{n}{2} - m}\).
Therefore, the probability that the model will generate a network with \(m\) links is \(\prob{m} = \binom{\binom{n}{2}}{m} p^{m} (1-p)^{\binom{n}{2} - m}\) (i.e., the probability of such network times the number of possible networks).
This corresponds to  a binomial distribution \(B(\binom{n}{2}, p)\).
One simple consequence of that is that the expected value for the number of links \(\expval{m} = \sum_{m=0}^{\binom{n}{2}} m \prob{m} = \binom{n}{2} p\).
The expected value for the average degree of a network generated with this model is deduced in equation~\ref{eq:avg-degree-erdos-model}.
This value is also often called \(c\).
The probability that an arbitrary node has a degree of exactly \(k\) is given by \(p(k) = \binom{n-1}{k} p^{k} (1-p)^{n-1-k}\) (i.e., \(k\) of its possible \(n-1\) links must exist and there are \(\binom{n-1}{k}\) possible combinations for the \(k\) links).
Therefore, the degree distribution of this model is a binomial distribution as well.
However, it is also possible to approximate the degree distribution with an Poisson distribution \(p(k) = \exp(-c) \frac{c^{k}}{k!}\) for large values of \(n\).

\begin{equation}
  c = \expval{d(G)} = \sum_{m=0}^{\binom{n}{2}} \frac{2m}{n} \prob{m} = \frac{2}{n} \sum_{m=0}^{\binom{n}{2}} m \prob{m} = \frac{2}{n} \binom{n}{2} p = (n-1) p
  \label{eq:avg-degree-erdos-model}
\end{equation}

A nice property of the Erdős–Rényi model is that it can be used to study the formation of giant components in networks.
A \emph{giant component} is a component that contains a large fraction of the nodes.
It is interesting that even such a simple model can be used to study a phenomenon that is part of many real-world networks.
However, there are also quite a few problems with this model.
The degrees in real-world networks are usually not binomial, respectively Poisson, distributed.
The formation of hubs in networks usually requires a power-law degree distribution.
Other examples for a shortcomings of the model is the inability to generate community structures and inadequate average path lengths.


\subsection{The Barabási-Albert model}

One model that addresses the problem of missing power-law degree distributions is the Barabási-Albert (BA) model~\cite{Barabasi2002}.
The model is named after its creators Réka Albert and Albert-László Barabási.
It tries to emulate the dynamic process that is responsible for the creation of scale-free degree distributions and yields a the generated network as result.
One of the main differences to the ER model is that the size of the network is not fixed.
The model starts with an small number of nodes and adds new nodes to the network over time (i.e., the network grows).
A newly added node then forms links with already existing nodes.
Which other nodes are chosen depends on how important the other nodes are.
The more important a node is, the more likely it is that the new nodes forms a connection with it.
This process is called \emph{preferential attachment}.
It can, for example, be used to describe the behavior of new users in social networks (i.e., new users tend to form ties with already established users) or that new websites on the web link to already popular ones because they are easier to find \todo{find better examples with references to papers?}.
More formally, the model starts with a small number \(m_{0}\) of nodes and the following two steps are repeated in every time step:

% examples at:http://barabasi.com/networksciencebook/chapter/5#origins

\begin{enumerate}
    \item add a new node to the network
    \item choose \(m \leq m_{0}\) already existing nodes at random proportional to their degree and form a link with them
\end{enumerate}

This means that in this model the degree of a node is a measure of its popularity  and a existing node \(v_{i}\) will be selected with a probability \(\Pi(v_{i})=\frac{d(v_{i})}{\sum_{j} d(v_{j})}\) to form a link.
The process yields after \(t\) time steps a network that consists of \(m_{0} + t\) nodes and \(mt\) links.

It can be shown, using different methods (e.g., continuum theory, master equations, and numerically), that the node degrees follow a power-law distribution with an degree exponent of \(\gamma = 3\).
Furthermore, asymptotically does \(\gamma\) not depend on \(m\), the number of links that are generated in each iteration.
The degree distribution is also (asymptotically) independent on the time, and therefore on the size of the network.
This is also a property of the model and reflects the fact that there exists real-world networks with a power-law degree distribution with different sizes.
However, like the ER model, the BA model has its shortcomings as well.
For example, the average path length of generated networks does not comply with real-world networks.
However, they are more realistic than the path lengths generated by the ER model.
Another property that cannot be reproduced by this model are the community structures that many real-world, and especially social, networks have~\cite{Reid2011}.

Another interesting question regarding the Barabási-Albert model is if both used mechanisms, the network growth and the preferential attachment, are necessary to produce a scale-free network.
The result of numerical simulations and formal tests of the model with either of the two mechanisms missing is that both are required.
Missing preferential attachment results in exponentially distributed node degrees and the missing network growth leads to a power-law degree distribution in the beginning, but it changes to a normal distribution over time.
This indicates that in fact both mechanisms are required to yield a network with the scale-free property.


%% ========================================================================
%% ========================================================================


\section{User Activity Models}
\label{sec:user-activity-models}

The modeling of the activity of users in complex systems (e.g., in social networks) can be a challenging task.
Usually the actual activities, such as the writing of an e-mails, posts on  Facebook, or tweets, are not of particular interest.
More relevant is how are these events or activities laid out in time and what  the distribution of intervals between two consecutive events is (i.e., the inter-event time distribution).
Multiple models that try to capture patterns of human activities based on different approaches are discussed in this section.

\subsection{Stochastic Models}

One of the simplest methods to model user activity is by using a Poisson process to describe the inter-activity times~\cite{Masuda2016, Vazquez2006}.
This stochastic process is defined by the event rate \( \lambda \), which states how often a event should occur in a given time window.
Two important properties of the Poisson process are that the inter-activity times are exponentially distributed and independent of each other.
This leads to the effect that events take place in regular intervals (i.e., at the given rate) and that it is almost impossible to have long periods of time between to consecutive activities.
However, it has been shown, that a lot of human activity patterns (e.g., email communication) cannot be modeled very accurately be a Poisson process due to its assumptions.
A lot of activities are executed in bursts, followed by longer periods of inactivity.
For example, a person may have a dedicated time in the day for answering emails.
This behavior can be much better explained by a power-law distribution of the inter-activity times because its long tail allows for longer inactivity periods.
There are, however, approaches that try to tackle this problem that are using extensions of Poisson processes.
For example, \citet{Malmgren2008} use a mixture of homogeneous and non-homogeneous Poisson processes to model user e-mail activity more precisely.
The rate of a non-homogeneous Poisson process does depend on the time, whereas the rate of a homogeneous process is constant.

A approach that does not only generate power-law distributed inter-event times, but also captures other patterns of human behavior, such as periodic spikes (e.g., higher activity every 24 hours) or a bimodal distribution of inter-event times (e.g., phases of high activity that are separated by phases of rest) was proposed by \citet{Costa2015}.
Their Rest-Sleep-and-Comment (RSC) model is based on the idea that a user can be in one of multiple states.
In the active state, a user generates events with a certain probability at some rate, which depends on how much time has passed since the last event.
The rest and sleep states are used to model the inactivity of a user.
The difference is that the rest state produces null-events (i.e., it increments the time) at a certain rate, whereas the sleep state is used to increment only once, but by a larger amount.
A active user can become inactive (i.e., go to the rest state) or stay active.
A user in the rest state can either become active, stay inactive, or go to the sleep state.
The user can not stay in the sleep state, only go into the rest state again.
The state transition probabilities are parameters of the model.
This model was the foundation for a classifier, that is able to detect whether a activity sequence was generated by a bot or by a human with very high accuracy.

Another possibility to model the user activity in social networks is by using coupled Hidden Markov Models (CHMMs)~\cite{Raghavan2013}.
The Markov model has two hidden states that describe the user activity (active or inactive) and yields inter-activity times with respect to the current state.
The CHMM model takes the social network influence of other users into account by explicitly coupling the stochastic processes of groups of people.
This is done by letting the transition probabilities between the states of the HMM for a single user be dependent on the activity of other users, that are in the circle of friends of the user (i.e., neighbors in the social network).
If the activity of the neighbors exceeds a certain threshold the probability that a user becomes active is larger.
The results show that this model is able to learn the complex human activity patterns and allows predictions with high accuracy compared to other methods.

\subsection{Queuing Models}

One approach that archives to model human activity with a more suitable power-law distributions are queuing models~\cite{Vazquez2006}.
The idea here is to think of the user as a queue that is constantly filled with new tasks (e.g., answer a email, go shopping, do the dishes,\ldots).
Each task takes a certain amount of time to finish and is prioritized by the user on arrival.
Furthermore, the queue is usually bounded in size, since the user can only keep track of a certain amount of tasks at a time.
At each time step the user selects the task with the highest priority from the queue and executes it.
It can be shown that the time it takes for a task to be handled (i.e., the waiting time) follows a power-law distribution.
There is evidence that the waiting time distribution of the queuing model is responsible for the inter-activity time power-law distribution of a specific activity, due to the fact that persons tend to group tasks in categories and reinserting them into the queue with a lower priority after they are done.
For example, a person does not keep track of every unanswered email in the queue, but has a \enquote{answer email} task that contains all emails that need to be replied-to.
Therefore, answering multiple emails in a short period of time, followed by a longer period of no email correspondence due to other tasks with higher priority.

\subsection{Time-varying Network Models}
\label{subsec:time-varying-network-models}

The earlier discussed user activity models are designed to only describe the activity profile of a single user, or require at least a separate stochastic process for each one.
However, there are also models that allow the description of the activities of multiple users using time-varying networks (i.e., as contact sequences).
The difference between models for temporal networks and network models described in~\autoref{sec:network-models} is that the models for static networks are connectivity driven~\cite{Perra2012a}.
This means that they are laid out to generate specific topological properties (e.g., the formation of community structures, or short average path lengths) in the networks, but do not include the the dynamic processes that are forming these structures.
One of the simplest methods to generate a time-varying network of user activity is described by \citet{Holme2013}.
The idea is to generate a static network and assign each link a set of time stamps that represents the contacts between the two nodes.
In the first step of this model a static network is generated using the configuration model~\cite[cf. sec. 13.2]{Newman2010}.
This model assigns a number, drawn from a probability distribution (e.g., a power-law distribution), to each node in the network.
This number represents the number of \enquote{half edges} of the node.
These \enquote{half edges} can be seen a dangling edges that will be connected at random to other \enquote{half edges} of different nodes.
Therefore, this number is the degree of the node.
Self-loops and parallel edges are avoided in the matching process to generate a simple static network.
In the next step each link in network is assigned a time span at random in which contacts are possible (i.e., the activity interval).
In the last step of this approach, a time series of events is generated by drawing inter-event times from a power-law distribution.
The time series is then split into parts and mapped onto the activity intervals, thus, generating a contact sequence.

A different approach by~\citet{Perra2012a} is based on the idea of activity potentials.
Each node \(v_{i}\) in the network is assigned a quantity called the activity potential \(x_{i}\), which is the probability that the node will be active in a time window \(\Delta t\).
The activity potentials of real-world networks can be determined by calculating the ratios of the number of interactions of each user in a time window to the total number of interactions.
This usually yields long tailed activity potential probability distributions, which corresponds to typical heterogeneous human activity patterns~\cite{Vazquez2006, Jo2012}.
Furthermore, the size of the time window that is used to estimate the probabilities seems not to effect the resulting distribution in a significant way.
The first step of this activity-driven model is to initialize each node in the network by assigning it a activity/firing rate \(a_{i} = \eta x_{i}\), where the activity potential is drawn from a suitable probability distribution \( f(x) \) and \( \eta \) is a re-scaling factor that is chosen in such a way that the expected number of active node in the time window is \(\eta \expval{x} n\).
The range of possible activity potential values is \(x_{i}\ \in [\varepsilon, 1]\).
The activity potential has a lower bound \( \varepsilon \) to avoid possible divergences of the distribution near zero.
After the setup phase the time-varying network of activities is generated.
It follows the idea of representing the temporal network as a sequence of graphs (see \autoref{sec:time-varying-networks}), which are called instantaneous networks in the context of this model.
For each time step \(t\) the following steps are repeated:

\begin{enumerate}
    \item Create a new network \(G_{t}\) that contains all nodes but has no links yet.
    \item Every node \(v_{i}\) becomes active with probability \(a_{i} \Delta t\). Active nodes choose \(m\) distinct other nodes uniformly at random and form a link with them.
\end{enumerate}

Since every active node creates \(m\) links, the cardinality of the edge set is given by \(|E_{t}| = m \eta \expval{x} n\).
Therefore, the average degree of the instantaneous network at time \(t\) is \(d(G_{t}) = \frac{2|E_{t}|}{n} = \frac{2 m \eta \expval{x} n}{n} = 2 m \eta \expval{x}\).
The probability that a node becomes active does not change over time and is, therefore, also independent of previous activities.
This resembles the problem already encountered with Poisson processes models.
The inter-event times for the node \(v_{i}\) will eventually be exponential distributed \(\varphi_{i}(\tau) = a_{i} \exp(-a_{i} \tau)\)~\cite{Moinet2016}.
Additionally, it is not very realistic in the sense that every node selects its neighbors in each iteration uniformly at random, which leads to networks with a random structure.
Users are usually prone to repeat previous communication~\cite{Karsai2014}.
Nevertheless, this model possesses a few considerable advantages.
First, and most important, it produces not only activities for a single user, but it generates snapshots of the user activities for a complete network for each time window.
Additionally, it is a very simple model.
It only needs a few parameters and the activity potential distribution is responsible for the dynamical behavior in the network.
Furthermore, this model can be used to explain the formation heterogeneous structures (i.e., hubs) in networks over longer periods of time.
This is done by examining the integrated network \(G_{T} = \bigcup_{t=0}^{T} G_{t}\), which the union of all instantaneous networks up to the time stamp \(T\).
It can be shown that the  degree distribution of this integrated network has the form \(p_{T}(k) \sim f(\frac{k}{T m \eta})\).
Therefore, it is up to a re-scaling factor, the same as the activity potential distribution.
The model can generate scale-free networks, if the activity potential is a power-law distributed.
The resulting hubs are not caused by preferential attachment like in other models, but due to the heterogeneous activity profiles of the nodes.
The re-scaling factor emerges from the fact that the model does not capture all features of real-world networks, like memory effects (e.g., links that were formed in earlier instantaneous networks are more likely to be formed later again).

Regardless of its simplicity, this activity-driven model can help to understand topological patterns and the dynamics of systems (e.g., epidemic spreading processes).
\citet{Starnini2013} study the topological properties of this model in a more formal way by mapping it onto a hidden variables network model.
The idea of hidden variables models is that the probability of the formation of a link between two nodes depends on some underlying characteristic of the nodes (i.e., the hidden variables).
In this case the hidden variable is the activity potential.
A network that was generated using this model fully depends on probability distributions that are related to the hidden variables.
Therefore, topological properties also depend on these probability distributions and can be expressed with respect to them.
The degree distribution of the integrated network could be verified using this more formal approach.
In addition, they showed that the clustering coefficient of the network is rather small and comparable to the clustering coefficient of random networks.
They also propose to use the hidden-variable approach to study possible extensions of the model, which is for example done for the NoPAD model~\cite{Moinet2015}, which is briefly discussed later in this section.

The activity-driven model is also a fundamental framework for many other studies that use it as start point for their work.
For example, \citet{Perra2012b} use this model to study random walks on temporal networks, or \citet{Rizzo2016} are applying this model for their research about the spreading the of the infectious Ebola disease in Liberia.
Another paper by \citet{Rizzo2014} uses the activity-driven network framework to study how an epidemic effects the behavior of persons.
They show that a reduction of the activity potential of persons, due to the fact that there are already ill or because they are trying to protect them self from the disease, may help the slow down the spreading process.
A paper on a similar topic by \citet{Liu2014} proposes a framework to develop strategies on how to contain the spreading of diseases.
\citet{Mistry2015} use the model to explore the spreading of opinions in social networks.
They show that activists can  spread messages across the population more effectively and can help to reduce the cost of campaigns.

On the other hand, others try to improve the model by making it more realistic by implement additional mechanisms.
\citet{Laurent2015} adds additional social mechanisms (e.g., memory) to the model to allow for the formation of communities on the integrated network.
Another extension by \citet{Moinet2015, Moinet2016} solves the problem of inaccurate inter-events times by making the activity potential time depended.
This model is known as the non-poissonian activity-driven (NoPAD) model and can generate inter-event time distributions that can also be observed in real-world networks.
\citet{Wang2016} proposed the Activity-Security-Trust (AST) model, which not only considers activity as the explicit driving force behind dynamic processes, but also incorporates the implicit factors security and trust.
Trust can be seen as the belief in honesty or fairness between two nodes and influences the possible link formation between them.
The second extension, the security level, is like the activity potential a property of each node that determines how well a node is prepared against possible attacks.
It can be seen as the probability of a node to receive a connection from another one.
\citet{Sunny2015} adds link lifetimes to the activity-driven framework.
Every time a link is formed it is assigned a lifetime, that is drawn at random from a probability distribution.
This link may then be part of multiple consecutive instantaneous networks
and is only removed after its lifetime has decayed, which is different to the simple activity-driven model, where links are meant to be instantaneous and are deleted after every time step.
The authors use this new introduces mechanism to study how well link lifetimes are suited to model disease spreading processes.


%% ========================================================================
%% ========================================================================


\section{Peer Influence}
\label{sec:peer-influence}
